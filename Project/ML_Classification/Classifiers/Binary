import IPython
import pyspark
from IPython.core.display import HTML
display(HTML("<style>pre { white-space: pre !important; }</style>"))

from pyspark.sql import SparkSession
spark = SparkSession \
    .builder \
    .appName("Binary") \
    .master("local[*]") \
    .config("spark.some.config.option", "value") \
    .getOrCreate()

from google.colab import drive
drive.mount('/content/drive')
dataset = spark.read.csv('drive/My Drive/UNSW-NB15.csv',inferSchema=True, header =True)\
.toDF("srcip", "sport", "dstip", "dsport", "proto", "state", "dur", "sbytes", "dbytes", "sttl", "dttl",
        "sloss", "dloss", "service", "Sload", "Dload", "Spkts", "Dpkts", "swin", "dwin", "stcpb", "dtcpb",
        "smeansz", "dmeansz", "trans_depth", "res_bdy_len", "Sjit", "Djit", "Stime", "Ltime", "Sintpkt", "Dintpkt",
        "tcprtt", "synack", "ackdat", "is_sm_ips_ports", "ct_state_ttl", "ct_flw_http_mthd", "is_ftp_login", "ct_ftp_cmd",
        "ct_srv_src", "ct_srv_dst", "ct_dst_ltm", "ct_src_ ltm", "ct_src_dport_ltm", "ct_dst_sport_ltm", "ct_dst_src_ltm",
        "attack_cat", "Label")

#Counting NAN values for preprocessing
from pyspark.sql.functions import col,isnan, when, count
dataset.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in dataset.columns]).show()

#Dropping attack_cat column
dataset=dataset.drop("attack_cat")
dataset.show()
dataset.printSchema()

from pyspark.ml.feature import StringIndexer
string_cols = ["srcip","dstip","proto","state","service"]
for column in list(string_cols):
  stringIndexer = StringIndexer(inputCol=column, outputCol="indexed_"+column, handleInvalid="error")
  model = stringIndexer.fit(dataset)
  dataset = model.transform(dataset)

dataset=dataset.drop("srcip","dstip","proto","state","service")

#combine all the features in one single feature vector.
cols=dataset.columns
cols.remove("Label")

# Let us import the vector assembler
from pyspark.ml.feature import VectorAssembler
assembler = VectorAssembler(inputCols=cols,outputCol="features")

# Now let us use the transform method to transform our dataset
dataset=assembler.transform(dataset)
dataset.select("features").show(truncate=False)

#Standard Sclarizer
from pyspark.ml.feature import StandardScaler
standardscaler=StandardScaler().setInputCol("features").setOutputCol("Scaled_features")
dataset=standardscaler.fit(dataset).transform(dataset)
dataset.select("features","Scaled_features").show(5)

#Train, test split
train, test = dataset.randomSplit([0.8, 0.2], seed=12376)

#imbalance in the dataset, observe the use of Where
dataset_size=float(train.select("Label").count())
numPositives=train.select("Label").where('Label == 1').count()
per_ones=(float(numPositives)/float(dataset_size))*100
numNegatives=float(dataset_size-numPositives)
print('The number of ones are {}'.format(numPositives))
print('Percentage of ones are {}'.format(per_ones))

BalancingRatio= numNegatives/dataset_size
print('BalancingRatio = {}'.format(BalancingRatio))

# balance
train=train.withColumn("classWeights", when(train.Label == 1,BalancingRatio).otherwise(1-BalancingRatio))
train.select("classWeights").show(5)

#Building a classification model using Logistic Regression (LR)
from pyspark.ml.classification import LogisticRegression
lr = LogisticRegression(labelCol="Label",weightCol="classWeights",maxIter=10)
model=lr.fit(train)

predict_train=model.transform(train)
predict_test=model.transform(test)
predict_test.select("Label","prediction").show(10)

#Evaluating the model
from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator=BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol="Label")

# We have only two choices: area under ROC and PR curves :-(
auroc = evaluator.evaluate(predict_test, {evaluator.metricName: "areaUnderROC"})
print("Area under ROC Curve: {:.4f}".format(auroc))
predict_test.select("Label","prediction","probability").show(15)
print(model.summary)

import matplotlib.pyplot as plt
pr = model.summary.pr.toPandas()
plt.plot(pr['recall'],pr['precision'])
plt.ylabel('Precision')
plt.xlabel('Recall')
plt.show()
print("Model Accuracy",model.summary.accuracy)
print("FP rate",model.summary.falsePositiveRateByLabel)
print("TR rate",model.summary.truePositiveRateByLabel)